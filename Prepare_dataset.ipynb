{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:58:49.967617Z",
     "start_time": "2022-05-10T01:58:49.725079Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "os.getcwd()\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import re \n",
    "import random \n",
    "import numpy as np\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from tqdm import tqdm\n",
    "import heapq\n",
    "\n",
    "from CrawlingMLMovieDescriptionFromTMDB import *\n",
    "\n",
    "'''\n",
    "------------------------------------------------------------------------------------\n",
    "|Download the original dataset of MovieLens25M (ML) and AmazonMovie(AM): \n",
    "|    ML:  grouplens.org/datasets/movielens/25m/ \n",
    "|    AM:  jmcauley.ucsd.edu/data/amazon/\n",
    "-------------------------------------------------------------------------------------\n",
    "'''\n",
    "\n",
    "\n",
    "AM_data_path = \" \"  # the AmazonMovie document path\n",
    "ML_data_path = \" \"  # the MovieLens25M document path\n",
    "\n",
    "save_file = \"./Datasets/\"\n",
    "\n",
    "df_AmazonMovie_sub = pd.read_csv(AM_data_file + \"AmazonMovieTitle.csv\")\n",
    "df_AmazonMovieRating = pd.read_csv(AM_data_file + \"AmazonMoiveRating.csv\")\n",
    "\n",
    "\n",
    "rating_file_path = \"ratings.csv\"\n",
    "df_ML = pd.read_csv(ML_data_path + \"ratings.csv\")\n",
    "df_movies = pd.read_csv(ML_data_path + \"movies.csv\")\n",
    "\n",
    "'''\n",
    "------------------------------------------------------------------------------------\n",
    "|Run the following code to crawl the textual descriptions for movies in MovieLens dataset. \n",
    "|This code will generate a dictionary file (Dict_MovieId2description.npy), key: movie_id -> value: movie_description\n",
    "\n",
    "GetMLMovieDescription(ML_data_path, save_path)\n",
    "MergeMLMovieDescription(file)\n",
    "\n",
    "-------------------------------------------------------------------------------------\n",
    "'''\n",
    "dict_id2descripton = np.load(save_file + \"Dict_MovieId2description.npy\", allow_pickle=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T01:58:50.616345Z",
     "start_time": "2022-05-10T01:58:50.610547Z"
    },
    "code_folding": [
     0,
     6,
     9,
     79
    ]
   },
   "outputs": [],
   "source": [
    "def FilterDataframeByList(target_data, col, col_name):\n",
    "    df_col = pd.DataFrame(col)\n",
    "    df_col.columns = [col_name]\n",
    "    output = pd.merge(target_data, df_col, how='inner', left_on=[col_name], right_on=[col_name])\n",
    "    return output\n",
    "\n",
    "def ToList(x):\n",
    "    return list(x)\n",
    "\n",
    "def Amazon_Data_Pareprocess(df_AmazonMovie_sub, df_AmazonMovieRating, MinNumOfRatingPerUser, MinNumOfRatingPerItem, MaxNumOfRatingPerUser, MaxNumOfRatingPerItem, start_time):\n",
    "    \n",
    "    df_AmazonMovieRating = df_AmazonMovieRating[[\"rating\",\"account_id\", \"deal_id\", \"UnixTime\"]]\n",
    "    df_AmazonMovieRating[\"time\"] = pd.to_datetime(df_AmazonMovieRating[\"UnixTime\"], unit=\"s\")\n",
    "    df_AmazonMovieRating[\"time\"] = df_AmazonMovieRating.time.dt.date\n",
    "    df_AmazonMovieRating = df_AmazonMovieRating.loc[df_AmazonMovieRating.rating ==5]\n",
    "\n",
    "    min_time = df_AmazonMovieRating.time.min()\n",
    "    max_time = df_AmazonMovieRating.time.max()\n",
    "    print(f\"Time Zone: ({min_time}ï½ž{max_time})\")\n",
    "    \n",
    "    avaluable_items = list(set(df_AmazonMovieRating.deal_id.unique()) & set(df_AmazonMovie_sub.deal_id.unique()))\n",
    "    df_T = FilterDataframeByList(df_AmazonMovieRating, avaluable_items, \"deal_id\")\n",
    "    \n",
    "    df_AmazonMovieRating_sub = df_T.loc[df_T.time > start_time]\n",
    "\n",
    "    filted_item_1 = df_AmazonMovieRating_sub.deal_id.value_counts().keys()[:(df_AmazonMovieRating_sub.deal_id.value_counts().values >= MinNumOfRatingPerItem).sum()]\n",
    "    filted_item_2 = df_AmazonMovieRating_sub.deal_id.value_counts().keys()[:(df_AmazonMovieRating_sub.deal_id.value_counts().values <= MaxNumOfRatingPerItem).sum()]\n",
    "    item_list = set(filted_item_1) & set(filted_item_2)\n",
    "    df_AmazonMovieRating_sub = FilterDataframeByList(df_AmazonMovieRating_sub, item_list, \"deal_id\")\n",
    "\n",
    "    filted_user_1 = df_AmazonMovieRating_sub.account_id.value_counts().keys()[:(df_AmazonMovieRating_sub.account_id.value_counts().values >= MinNumOfRatingPerUser).sum()]\n",
    "    filted_user_2 = df_AmazonMovieRating_sub.account_id.value_counts().keys()[:(df_AmazonMovieRating_sub.account_id.value_counts().values <= MaxNumOfRatingPerUser).sum()]\n",
    "    user_list = set(filted_user_1) & set(filted_user_2)\n",
    "    df_AmazonMovieRating_sub = FilterDataframeByList(df_AmazonMovieRating_sub, user_list, \"account_id\")\n",
    "    \n",
    "    n_users = len(df_AmazonMovieRating_sub.account_id.unique())\n",
    "    n_items = len(df_AmazonMovieRating_sub.deal_id.unique())\n",
    "    n_interaction = df_AmazonMovieRating_sub.shape[0]\n",
    "    print(f'user number: {n_users}')\n",
    "    print(f'item number: {n_items}')\n",
    "    print(f'interaction number: {n_interaction}')\n",
    "    #df_AmazonMovieRating_sub.to_csv(data_file + \"Dataset_AmazonMovie.csv\", )\n",
    "    \n",
    "    \n",
    "    df_AmazonMovie_filted = FilterDataframeByList(df_AmazonMovie_sub, df_AmazonMovieRating_sub.deal_id.unique(), \"deal_id\")\n",
    "    import re \n",
    "    dr = re.compile(r'<[^>]+>|\\\\t|\\\\n|\\\\\\'|\\'|\\[|\\]', re.S)\n",
    "    df_AmazonMovie_filted.description = df_AmazonMovie_filted.description.map(lambda x: dr.sub(\"\",x))\n",
    "    #df_AmazonMovie_filted.to_csv(data_file + \"Dataset_MovieTitles.csv\")\n",
    "    \n",
    "    return df_AmazonMovieRating_sub, df_AmazonMovie_filted\n",
    "    \n",
    "def ML_Data_Preprocess(is_target, df_ML, df_movies, dict_id2descripton):\n",
    "    \n",
    "    df_ML[\"time\"] = pd.to_datetime(df_ML[\"timestamp\"], unit=\"s\")\n",
    "    df_ML[\"time\"] = df_ML.time.dt.date\n",
    "    df_ML = df_ML.loc[df_ML.rating >= 5]\n",
    "    df_ML = FilterDataframeByList(df_ML, dict_id2descripton.keys(), 'movieId')\n",
    "    df_ML_sub = df_ML.loc[df_ML.time > datetime.date(2016,9,30)]\n",
    "    df_ML_sub = df_ML_sub.loc[df_ML_sub.time < datetime.date(2018,10,1)]\n",
    "    \n",
    "    if is_target:\n",
    "        df_ML_sub = FilterSourceData(df_ML_sub, \"userId\", \"movieId\", alpha=20, beta=5)\n",
    "    \n",
    "    n_users = len(df_ML_sub.userId.unique())\n",
    "    n_items = len(df_ML_sub.movieId.unique())\n",
    "    n_interaction = df_ML_sub.shape[0]\n",
    "    print(f'user number: {n_users}')\n",
    "    print(f'item number: {n_items}')\n",
    "    print(f'interaction number: {n_interaction}')\n",
    "    #df_ML_sub.to_csv(data_file + \"./Dataset_MovieLens25M.csv\")\n",
    "    \n",
    "    textual_file_path = \"/ml-25m/movies.csv\"\n",
    "    df_movies = pd.read_csv(data_path + textual_file_path)\n",
    "    df_movies = FilterDataframeByList(df_movies, df_ML_sub.movieId.unique(), 'movieId')\n",
    "    #df_movies.to_csv(data_file + \"Dataset_MLMovieTitles.csv\")\n",
    "    \n",
    "    return df_ML_sub, df_movies\n",
    "\n",
    "def FilterSourceData(df_ss, account_id, deal_id, alpha=20, beta=5):\n",
    "    # alpha: filter out users who have num of interactions less than alpha. \n",
    "    # beta: the interactions have top beta tf-idf scores will be picked.\n",
    "    \n",
    "    dict_interactions_s = dict(df_ss.groupby(df_ss[account_id])[deal_id].apply(ToList))\n",
    "    df_ss[\"deal_id_str\"] = df_ss[deal_id].map(lambda x: str(x))\n",
    "    dict_interactions_str = dict(df_ss.groupby(df_ss[account_id])[\"deal_id_str\"].apply(ToList))\n",
    "    \n",
    "    data = np.array(list(dict_interactions_str.values()))\n",
    "    dictionary = Dictionary(data)\n",
    "    corpus = list(map(dictionary.doc2bow,data))\n",
    "    model = TfidfModel(corpus)\n",
    "    corpus_tfidf = model[corpus]\n",
    "    \n",
    "    tfidf_weight = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        tfidf_vec = []\n",
    "        dict_id_2_tfidf = dict(zip([x[0] for x in corpus_tfidf[i]], [x[1] for x in corpus_tfidf[i]]))\n",
    "        for token in dictionary.doc2idx(data[i]):\n",
    "            try:\n",
    "                tfidf_vec.append(dict_id_2_tfidf[token])\n",
    "            except:\n",
    "                tfidf_vec.append(0.)\n",
    "        tfidf_weight.append(tfidf_vec)\n",
    "        \n",
    "    dict_int = {}\n",
    "    item_lst = []\n",
    "    user_lst = []\n",
    "    user_list = list(dict_interactions_str.keys())\n",
    "    for i in range(len(tfidf_weight)):\n",
    "        a = np.array(tfidf_weight[i])\n",
    "        if len(a)>=alpha:\n",
    "            idx = heapq.nlargest(beta, range(len(a)), a.take)\n",
    "            items = np.array(dict_interactions_s[user_list[i]])[idx]\n",
    "        else:\n",
    "            continue\n",
    "            #items = np.array(dict_interactions_s[user_list[i]])\n",
    "        dict_int[user_list[i]] = items\n",
    "        item_lst.extend(items)\n",
    "        user_lst.extend([user_list[i]] * len(items))    \n",
    "    \n",
    "    df_tmp = pd.DataFrame(user_lst)\n",
    "    df_tmp.columns = ['userId']\n",
    "    df_tmp['movieId'] = item_lst\n",
    "    return df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T05:46:25.012269Z",
     "start_time": "2022-04-01T05:46:16.868594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Zone: (1997-09-03ï½ž2018-10-03)\n",
      "user number: 8566\n",
      "item number: 6752\n",
      "interaction number: 39696\n"
     ]
    }
   ],
   "source": [
    "Rating_AmzMasT, Side_AmzMasT = Amazon_Data_Preprocess(df_AmazonMovie_sub, df_AmazonMovieRating, 3, 5, 5, 15, datetime.date(2017,6,30))\n",
    "Rating_AmzMasT.to_csv(save_file + \"Rating_AmzMasT.csv\")\n",
    "Side_AmzMasT.to_csv(save_file + \"Side_AmzMasT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T06:04:27.783366Z",
     "start_time": "2022-04-01T06:04:17.910683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Zone: (1997-09-03ï½ž2018-10-03)\n",
      "user number: 22046\n",
      "item number: 7814\n",
      "interaction number: 104216\n"
     ]
    }
   ],
   "source": [
    "Rating_AmzMasS, Side_AmzMasS = Amazon_Data_Preprocess(df_AmazonMovie_sub, df_AmazonMovieRating, 3, 10, 10, 15, datetime.date(2016,9,30))\n",
    "Rating_AmzMasS.to_csv(save_file + \"Rating_AmzMasS.csv\")\n",
    "Side_AmzMasS.to_csv(save_file + \"Side_AmzMasS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T06:18:12.351583Z",
     "start_time": "2022-04-01T06:17:54.224282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user number: 18232\n",
      "item number: 14435\n",
      "interaction number: 421803\n"
     ]
    }
   ],
   "source": [
    "Rating_MLasS, Side_MLasS = ML_Data_Preprocess(0)\n",
    "Rating_MLasS.to_csv(save_file + \"Rating_MLasS.csv\")\n",
    "Side_MLasS.to_csv(save_file + \"Side_MLasS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T06:19:52.356967Z",
     "start_time": "2022-04-01T06:19:28.092468Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/torch_1.1.0/lib/python3.7/site-packages/ipykernel_launcher.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 18232/18232 [00:03<00:00, 4758.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user number: 6289\n",
      "item number: 9873\n",
      "interaction number: 31445\n"
     ]
    }
   ],
   "source": [
    "Rating_MLasT, Side_MLasT = ML_Data_Preprocess(1)\n",
    "Rating_MLasT.to_csv(save_file + \"Rating_MLasT.csv\")\n",
    "Side_MLasT.to_csv(save_file + \"Side_MLasT.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_1.1.0",
   "language": "python",
   "name": "torch_1.1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
